{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e36170-bb71-428b-bd87-e442c90352f2",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 18px; line-height: .7;\">Md Sen Bin Mustafiz</p>\n",
    "<p style=\"text-align: center; line-height: 1.2;\">\n",
    "mbm52@njit.edu<br>\n",
    "NJIT ID: 31690921<br>\n",
    "24 Nov, 2024<br>\n",
    "Professor Yasser Abdullah<br>\n",
    "CS 634: Data Mining\n",
    "</p>\n",
    "<p style=\"text-align: center; font-size: 18px; line-height: .7;\">Final Project Report</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9758c961-821c-4713-954c-7443660d293a",
   "metadata": {},
   "source": [
    "A machine learning classifier is an algorithm used to determine the category or class of a data point. \n",
    "It is a supervised learning technique where the model is trained on labeled data, consisting of input features and their corresponding output labels. \n",
    "The classifier identifies patterns in the training data and uses this understanding to classify new data.\n",
    "\n",
    "Main Components of a Classifier:\n",
    "- Input Features: Characteristics or attributes of the data.  \n",
    "- Labeled Data: Data with known categories for training.  \n",
    "- Classification Model: The algorithm (e.g., Decision Tree, SVM, Neural Networks) that learns from the data.  \n",
    "- Output Class: The predicted category for the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea80f23-70c0-4c47-8c5a-4216fc60d425",
   "metadata": {},
   "source": [
    "A machine learning classifier relies on structured data to make accurate predictions, with **input features**, **labeled data**, \n",
    "and **output classes** playing crucial roles in its functioning. In this project I use Car Evaluation Database. It is based on a hierarchical decision model for evaluating car acceptability. It simplifies the decision structure by linking car acceptability directly to six input attributes: \n",
    "\n",
    "1. buying (v-high, high, med, low)\n",
    "2. maint (v-high, high, med, low)\n",
    "3. doors (2, 3, 4, 5-more)\n",
    "4. persons (2, 4, more)\n",
    "5. lug_boot (small, med, big)\n",
    "6. safety (low, med, high)\n",
    " \n",
    "The dataset contains 1,728 instances with no missing values and classifies the data into four categories:  \n",
    "\n",
    "1. unacceptable\n",
    "2. acceptable \n",
    "3. good \n",
    "4. very good\n",
    "\n",
    "This dataset is widely used for testing machine learning methods such as structure discovery and constructive induction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f839c87-10e8-4fea-94b4-1afdbd0e2081",
   "metadata": {},
   "source": [
    "**Classification Model:** In this project I used 3 different classification algorithms in Python. They are:\n",
    "1. Random Forest\n",
    "2. Na√Øve Bayes\n",
    "3. Bidirectional-LSTM\n",
    "\n",
    "In evaluating classification performance, I also used the 10-fold cross validation \n",
    "metho in every classification model.d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc3c0ed-bdd6-47dd-92ae-d9a1a246e1ee",
   "metadata": {},
   "source": [
    "### Importing the package\n",
    "\n",
    "Remove the # and import the package when you run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fbd88682-b2f8-4964-a801-734fcb79f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc5953b-99c0-4c4c-8646-e14436eade00",
   "metadata": {},
   "source": [
    "### Importing the libraries that are required for the project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93a6709c-d3a8-4491-834f-ebfa01071b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, brier_score_loss, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a37fd-e328-4289-b8ee-e4089cf509b9",
   "metadata": {},
   "source": [
    "### Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39299de7-9695-4a13-b1bb-6f4628b82f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('car.csv')  # csv file\n",
    "\n",
    "# Encode catagory\n",
    "label_encoders = {}\n",
    "for column in data.columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# divide \n",
    "X = data.drop(columns='class')\n",
    "y = data['class']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75670e8e-0333-42cd-8c63-e777358caf79",
   "metadata": {},
   "source": [
    "### 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "027d7011-37d9-4b3b-9ccd-f844d51dbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 10 fold\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2d517a-df59-4b3f-8c58-d53d6b64522c",
   "metadata": {},
   "source": [
    "## 1. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dd9b0a6-43d0-47d3-9be0-8c73094c0835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "rf_mod = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be5820-ca9c-42e1-b145-ee77cc187735",
   "metadata": {},
   "source": [
    "Here I used Random Forest classifier to calculate values like Confusion matrix, Sensitivity, Specificity, False Positive Rate,\n",
    "False Negative Rate, precision, F1 score, Balanced Accuracy, True Skill Statistic, Heidke Skill Score and AUC.\n",
    "The results for each fold are stored for overall evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3172b725-85db-4f4c-8120-f483538a8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty list to store values for each fold\n",
    "fold_values = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X), start=1):\n",
    "    # Splitting the data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]    # Train \n",
    "    rf_mod.fit(X_train, y_train)\n",
    "    y_pred = rf_mod.predict(X_test)\n",
    "    \n",
    "    # Confusion matrix \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tp = cm.diagonal()  # True Positives \n",
    "    fn = cm.sum(axis=1) - tp  # False Negatives \n",
    "    fp = cm.sum(axis=0) - tp  # False Positives\n",
    "    tn = cm.sum() - (fp + fn + tp)  # True Negatives \n",
    "\n",
    " \n",
    "    p = tp + fn\n",
    "    n = tn + fp\n",
    "    TPR = tp / (tp + fn)  # Sensitivity\n",
    "    TNR = tn / (tn + fp)  # Specificity \n",
    "    FPR = fp / (fp + tn)  # False Positive Rate \n",
    "    FNR = fn / (fn + tp)  # False Negative Rate\n",
    "    Precision = tp / (tp + fp)  # Precision \n",
    "    F1_measure = 2 * (Precision * TPR) / (Precision + TPR)  # F1 Score\n",
    "    Accuracy = accuracy_score(y_test, y_pred)\n",
    "    Error_rate = 1 - Accuracy\n",
    "    BACC = (TPR + TNR) / 2  # Balanced Accuracy\n",
    "    TSS = TPR - FPR  # True Skill Statistic \n",
    "    HSS = (2 * (tp * tn - fp * fn)) / ((tp + fn) * (fn + tn) + (tp + fp) * (fp + tn))  # Heidke Skill Score \n",
    "    \n",
    "    #  Brier Score \n",
    "    y_proba = rf_mod.predict_proba(X_test)  # Probabilities\n",
    "    brier_score = np.mean([(y_proba[:, i] - (y_test == i).astype(int)) ** 2 for i in range(y_proba.shape[1])])\n",
    "    \n",
    "    #  AUC \n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "    except ValueError:\n",
    "        auc = np.nan  #  NaN if calculation not meet\n",
    "    \n",
    "    # Store averaged values\n",
    "    fold_values.append([\n",
    "        tp.mean(), tn.mean(), fp.mean(), fn.mean(), p.mean(), n.mean(),\n",
    "        TPR.mean(), TNR.mean(), FPR.mean(), FNR.mean(),\n",
    "        Precision.mean(), F1_measure.mean(),\n",
    "        Accuracy, Error_rate, BACC.mean(), TSS.mean(), HSS.mean(),\n",
    "        brier_score, auc, Accuracy  # Acc_by_package_fn \n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441466e2-4ba6-487d-acbf-65fed2c18efa",
   "metadata": {},
   "source": [
    "### Printing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90176c0e-5178-467b-9e66-bf1648cc7162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold : 1</th>\n",
       "      <th>Fold : 2</th>\n",
       "      <th>Fold : 3</th>\n",
       "      <th>Fold : 4</th>\n",
       "      <th>Fold : 5</th>\n",
       "      <th>Fold : 6</th>\n",
       "      <th>Fold : 7</th>\n",
       "      <th>Fold : 8</th>\n",
       "      <th>Fold : 9</th>\n",
       "      <th>Fold : 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>41.500000</td>\n",
       "      <td>42.750000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>42.750000</td>\n",
       "      <td>42.250000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>128.000000</td>\n",
       "      <td>129.250000</td>\n",
       "      <td>128.250000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.500000</td>\n",
       "      <td>129.250000</td>\n",
       "      <td>128.750000</td>\n",
       "      <td>129.500000</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.940909</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.919795</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.966684</td>\n",
       "      <td>0.926556</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.991284</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.986434</td>\n",
       "      <td>0.993521</td>\n",
       "      <td>0.989436</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.998252</td>\n",
       "      <td>0.996296</td>\n",
       "      <td>0.989317</td>\n",
       "      <td>0.998106</td>\n",
       "      <td>0.993589</td>\n",
       "      <td>0.988126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>0.010564</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.010683</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.006411</td>\n",
       "      <td>0.011874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.059091</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.080205</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.033316</td>\n",
       "      <td>0.073444</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.887211</td>\n",
       "      <td>0.947984</td>\n",
       "      <td>0.932234</td>\n",
       "      <td>0.981707</td>\n",
       "      <td>0.991935</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.978247</td>\n",
       "      <td>0.994048</td>\n",
       "      <td>0.991284</td>\n",
       "      <td>0.984384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 measure</th>\n",
       "      <td>0.898857</td>\n",
       "      <td>0.964631</td>\n",
       "      <td>0.924262</td>\n",
       "      <td>0.946389</td>\n",
       "      <td>0.960187</td>\n",
       "      <td>0.975886</td>\n",
       "      <td>0.947760</td>\n",
       "      <td>0.961274</td>\n",
       "      <td>0.991284</td>\n",
       "      <td>0.957204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.959538</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>0.965318</td>\n",
       "      <td>0.982659</td>\n",
       "      <td>0.994220</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>0.976879</td>\n",
       "      <td>0.994220</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.976744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error_rate</th>\n",
       "      <td>0.040462</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.034682</td>\n",
       "      <td>0.017341</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BACC</th>\n",
       "      <td>0.963671</td>\n",
       "      <td>0.990350</td>\n",
       "      <td>0.954616</td>\n",
       "      <td>0.959722</td>\n",
       "      <td>0.967876</td>\n",
       "      <td>0.981490</td>\n",
       "      <td>0.957936</td>\n",
       "      <td>0.967803</td>\n",
       "      <td>0.992437</td>\n",
       "      <td>0.960730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSS</th>\n",
       "      <td>0.927343</td>\n",
       "      <td>0.980700</td>\n",
       "      <td>0.909231</td>\n",
       "      <td>0.919444</td>\n",
       "      <td>0.935752</td>\n",
       "      <td>0.962980</td>\n",
       "      <td>0.915873</td>\n",
       "      <td>0.935606</td>\n",
       "      <td>0.984873</td>\n",
       "      <td>0.921460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSS</th>\n",
       "      <td>0.885863</td>\n",
       "      <td>0.959523</td>\n",
       "      <td>0.909233</td>\n",
       "      <td>0.941380</td>\n",
       "      <td>0.958588</td>\n",
       "      <td>0.970889</td>\n",
       "      <td>0.935633</td>\n",
       "      <td>0.959601</td>\n",
       "      <td>0.984873</td>\n",
       "      <td>0.947713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brier score</th>\n",
       "      <td>0.023528</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>0.016835</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.021507</td>\n",
       "      <td>0.014860</td>\n",
       "      <td>0.012806</td>\n",
       "      <td>0.016254</td>\n",
       "      <td>0.021353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.994760</td>\n",
       "      <td>0.999809</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.999293</td>\n",
       "      <td>0.999260</td>\n",
       "      <td>0.998203</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>0.999815</td>\n",
       "      <td>0.999280</td>\n",
       "      <td>0.998764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acc_by_package_fn</th>\n",
       "      <td>0.959538</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>0.965318</td>\n",
       "      <td>0.982659</td>\n",
       "      <td>0.994220</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>0.976879</td>\n",
       "      <td>0.994220</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.976744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Fold : 1    Fold : 2    Fold : 3    Fold : 4    Fold : 5  \\\n",
       "TP                  41.500000   42.750000   41.750000   42.500000   43.000000   \n",
       "TN                 128.000000  129.250000  128.250000  129.000000  129.500000   \n",
       "FP                   1.750000    0.500000    1.500000    0.750000    0.250000   \n",
       "FN                   1.750000    0.500000    1.500000    0.750000    0.250000   \n",
       "P                   43.250000   43.250000   43.250000   43.250000   43.250000   \n",
       "N                  129.750000  129.750000  129.750000  129.750000  129.750000   \n",
       "TPR                  0.940909    0.987179    0.919795    0.925000    0.937500   \n",
       "TNR                  0.986434    0.993521    0.989436    0.994444    0.998252   \n",
       "FPR                  0.013566    0.006479    0.010564    0.005556    0.001748   \n",
       "FNR                  0.059091    0.012821    0.080205    0.075000    0.062500   \n",
       "Precision            0.887211    0.947984    0.932234    0.981707    0.991935   \n",
       "F1 measure           0.898857    0.964631    0.924262    0.946389    0.960187   \n",
       "Accuracy             0.959538    0.988439    0.965318    0.982659    0.994220   \n",
       "Error_rate           0.040462    0.011561    0.034682    0.017341    0.005780   \n",
       "BACC                 0.963671    0.990350    0.954616    0.959722    0.967876   \n",
       "TSS                  0.927343    0.980700    0.909231    0.919444    0.935752   \n",
       "HSS                  0.885863    0.959523    0.909233    0.941380    0.958588   \n",
       "Brier score          0.023528    0.012509    0.015283    0.016835    0.010279   \n",
       "AUC                  0.994760    0.999809    0.999194    0.999293    0.999260   \n",
       "Acc_by_package_fn    0.959538    0.988439    0.965318    0.982659    0.994220   \n",
       "\n",
       "                     Fold : 6    Fold : 7    Fold : 8    Fold : 9   Fold : 10  \n",
       "TP                  42.750000   42.250000   43.000000   42.500000   42.000000  \n",
       "TN                 129.250000  128.750000  129.500000  128.500000  128.000000  \n",
       "FP                   0.500000    1.000000    0.250000    0.500000    1.000000  \n",
       "FN                   0.500000    1.000000    0.250000    0.500000    1.000000  \n",
       "P                   43.250000   43.250000   43.250000   43.000000   43.000000  \n",
       "N                  129.750000  129.750000  129.750000  129.000000  129.000000  \n",
       "TPR                  0.966684    0.926556    0.937500    0.991284    0.933333  \n",
       "TNR                  0.996296    0.989317    0.998106    0.993589    0.988126  \n",
       "FPR                  0.003704    0.010683    0.001894    0.006411    0.011874  \n",
       "FNR                  0.033316    0.073444    0.062500    0.008716    0.066667  \n",
       "Precision            0.987500    0.978247    0.994048    0.991284    0.984384  \n",
       "F1 measure           0.975886    0.947760    0.961274    0.991284    0.957204  \n",
       "Accuracy             0.988439    0.976879    0.994220    0.988372    0.976744  \n",
       "Error_rate           0.011561    0.023121    0.005780    0.011628    0.023256  \n",
       "BACC                 0.981490    0.957936    0.967803    0.992437    0.960730  \n",
       "TSS                  0.962980    0.915873    0.935606    0.984873    0.921460  \n",
       "HSS                  0.970889    0.935633    0.959601    0.984873    0.947713  \n",
       "Brier score          0.021507    0.014860    0.012806    0.016254    0.021353  \n",
       "AUC                  0.998203    0.999171    0.999815    0.999280    0.998764  \n",
       "Acc_by_package_fn    0.988439    0.976879    0.994220    0.988372    0.976744  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# values to DataFrame\n",
    "values_df = pd.DataFrame(fold_values, columns=[\n",
    "    \"TP\", \"TN\", \"FP\", \"FN\", \"P\", \"N\", \"TPR\", \"TNR\", \"FPR\", \"FNR\", \"Precision\", \"F1 measure\",\n",
    "    \"Accuracy\", \"Error_rate\", \"BACC\", \"TSS\", \"HSS\", \"Brier score\", \"AUC\", \"Acc_by_package_fn\"\n",
    "])\n",
    "\n",
    "# Transpose \n",
    "value_df_rf = values_df.T\n",
    "value_df_rf.columns = [f\"Fold : {i+1}\" for i in range(value_df_rf.shape[1])]\n",
    "\n",
    "# Display\n",
    "value_df_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef54be-7249-482d-82a1-90b7a890ce32",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8a842c-a40d-4961-9afe-7613bb67c6ff",
   "metadata": {},
   "source": [
    "Here I used Naive Bayes classifier to calculate values like Confusion matrix, Sensitivity, Specificity, False Positive Rate, False Negative Rate, precision, F1 score, Balanced Accuracy, True Skill Statistic, Heidke Skill Score and AUC. \n",
    "The results for each fold are stored for overall evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf75059e-4f40-44ce-aed9-1b915e6afe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Naive Bayes classifier\n",
    "\n",
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c35e1d4-751e-4d0d-8378-007c45da06a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  empty list \n",
    "fold_value = []\n",
    "\n",
    "# Loop through each fold\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X), start=1):\n",
    "    # Splitting data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train \n",
    "    nb_model.fit(X_train, y_train)\n",
    "    y_pred = nb_model.predict(X_test)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tp = cm.diagonal()  # True Positives\n",
    "    fn = cm.sum(axis=1) - tp  # False Negatives\n",
    "    fp = cm.sum(axis=0) - tp  # False Positives \n",
    "    tn = cm.sum() - (fp + fn + tp)  # True Negatives\n",
    "    p = tp + fn\n",
    "    n = tn + fp\n",
    "\n",
    "   \n",
    "    TPR = tp / (tp + fn)  # Sensitivity (Recall) \n",
    "    TNR = tn / (tn + fp)  # Specificity\n",
    "    FPR = fp / (fp + tn)  # False Positive Rate\n",
    "    FNR = fn / (fn + tp)  # False Negative Rate \n",
    "    \n",
    "    #  Precision and F1_measure\n",
    "    Precision = np.divide(tp, (tp + fp), out=np.zeros_like(tp, dtype=float), where=(tp + fp) != 0)\n",
    "    F1_measure = np.divide(2 * (Precision * TPR), (Precision + TPR), out=np.zeros_like(TPR, dtype=float), where=(Precision + TPR) != 0)\n",
    "    \n",
    "    Accuracy = accuracy_score(y_test, y_pred)\n",
    "    Error_rate = 1 - Accuracy\n",
    "    BACC = (TPR + TNR) / 2  # Balanced Accuracy \n",
    "    TSS = TPR - FPR  # True Skill Statistic\n",
    "    HSS = (2 * (tp * tn - fp * fn)) / ((tp + fn) * (fn + tn) + (tp + fp) * (fp + tn))  # Heidke Skill Score\n",
    "    \n",
    "    #  Brier Score\n",
    "    y_proba = nb_model.predict_proba(X_test)  # Probabilities \n",
    "    brier_score = np.mean([(y_proba[:, i] - (y_test == i).astype(int)) ** 2 for i in range(y_proba.shape[1])])\n",
    "    \n",
    "    # AUC\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "    except ValueError:\n",
    "        auc = np.nan  #  NaN \n",
    "    \n",
    "    # averaged values \n",
    "    fold_value.append([\n",
    "        tp.mean(), tn.mean(), fp.mean(), fn.mean(),p.mean(),n.mean(),\n",
    "        TPR.mean(), TNR.mean(), FPR.mean(), FNR.mean(),\n",
    "        Precision.mean(), F1_measure.mean(),\n",
    "        Accuracy, Error_rate, BACC.mean(), TSS.mean(), HSS.mean(),\n",
    "        brier_score, auc, Accuracy  # Acc_by_package_fn \n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2409f4f-5f22-4f48-8be6-781906f73005",
   "metadata": {},
   "source": [
    "### Printing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3f2005c-e859-43d8-aa6e-96f6f314d3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Fold 6</th>\n",
       "      <th>Fold 7</th>\n",
       "      <th>Fold 8</th>\n",
       "      <th>Fold 9</th>\n",
       "      <th>Fold 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>25.250000</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>111.750000</td>\n",
       "      <td>114.250000</td>\n",
       "      <td>116.250000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>111.250000</td>\n",
       "      <td>115.500000</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>112.250000</td>\n",
       "      <td>113.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.470373</td>\n",
       "      <td>0.470138</td>\n",
       "      <td>0.503194</td>\n",
       "      <td>0.483714</td>\n",
       "      <td>0.467397</td>\n",
       "      <td>0.442149</td>\n",
       "      <td>0.485778</td>\n",
       "      <td>0.462508</td>\n",
       "      <td>0.483749</td>\n",
       "      <td>0.493374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.823838</td>\n",
       "      <td>0.846150</td>\n",
       "      <td>0.868231</td>\n",
       "      <td>0.862582</td>\n",
       "      <td>0.847381</td>\n",
       "      <td>0.812366</td>\n",
       "      <td>0.853926</td>\n",
       "      <td>0.851611</td>\n",
       "      <td>0.838830</td>\n",
       "      <td>0.855411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.176162</td>\n",
       "      <td>0.153850</td>\n",
       "      <td>0.131769</td>\n",
       "      <td>0.137418</td>\n",
       "      <td>0.152619</td>\n",
       "      <td>0.187634</td>\n",
       "      <td>0.146074</td>\n",
       "      <td>0.148389</td>\n",
       "      <td>0.161170</td>\n",
       "      <td>0.144589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.529627</td>\n",
       "      <td>0.529862</td>\n",
       "      <td>0.496806</td>\n",
       "      <td>0.516286</td>\n",
       "      <td>0.532603</td>\n",
       "      <td>0.557851</td>\n",
       "      <td>0.514222</td>\n",
       "      <td>0.537492</td>\n",
       "      <td>0.516251</td>\n",
       "      <td>0.506626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.379752</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.387741</td>\n",
       "      <td>0.394413</td>\n",
       "      <td>0.361048</td>\n",
       "      <td>0.227704</td>\n",
       "      <td>0.425887</td>\n",
       "      <td>0.356430</td>\n",
       "      <td>0.344046</td>\n",
       "      <td>0.369376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_measure</th>\n",
       "      <td>0.319360</td>\n",
       "      <td>0.295971</td>\n",
       "      <td>0.346246</td>\n",
       "      <td>0.291893</td>\n",
       "      <td>0.262175</td>\n",
       "      <td>0.245383</td>\n",
       "      <td>0.332591</td>\n",
       "      <td>0.290421</td>\n",
       "      <td>0.310952</td>\n",
       "      <td>0.334899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.583815</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.687861</td>\n",
       "      <td>0.612717</td>\n",
       "      <td>0.658960</td>\n",
       "      <td>0.572254</td>\n",
       "      <td>0.670520</td>\n",
       "      <td>0.601156</td>\n",
       "      <td>0.610465</td>\n",
       "      <td>0.627907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error_rate</th>\n",
       "      <td>0.416185</td>\n",
       "      <td>0.358382</td>\n",
       "      <td>0.312139</td>\n",
       "      <td>0.387283</td>\n",
       "      <td>0.341040</td>\n",
       "      <td>0.427746</td>\n",
       "      <td>0.329480</td>\n",
       "      <td>0.398844</td>\n",
       "      <td>0.389535</td>\n",
       "      <td>0.372093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BACC</th>\n",
       "      <td>0.647106</td>\n",
       "      <td>0.658144</td>\n",
       "      <td>0.685713</td>\n",
       "      <td>0.673148</td>\n",
       "      <td>0.657389</td>\n",
       "      <td>0.627257</td>\n",
       "      <td>0.669852</td>\n",
       "      <td>0.657059</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.674392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSS</th>\n",
       "      <td>0.294212</td>\n",
       "      <td>0.316288</td>\n",
       "      <td>0.371425</td>\n",
       "      <td>0.346296</td>\n",
       "      <td>0.314777</td>\n",
       "      <td>0.254515</td>\n",
       "      <td>0.339704</td>\n",
       "      <td>0.314119</td>\n",
       "      <td>0.322579</td>\n",
       "      <td>0.348785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSS</th>\n",
       "      <td>0.178148</td>\n",
       "      <td>0.178146</td>\n",
       "      <td>0.240213</td>\n",
       "      <td>0.192697</td>\n",
       "      <td>0.136996</td>\n",
       "      <td>0.109563</td>\n",
       "      <td>0.213132</td>\n",
       "      <td>0.175001</td>\n",
       "      <td>0.182451</td>\n",
       "      <td>0.227613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brier_score</th>\n",
       "      <td>0.155348</td>\n",
       "      <td>0.157572</td>\n",
       "      <td>0.139540</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.147899</td>\n",
       "      <td>0.171573</td>\n",
       "      <td>0.141456</td>\n",
       "      <td>0.173214</td>\n",
       "      <td>0.154961</td>\n",
       "      <td>0.163264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.816756</td>\n",
       "      <td>0.811708</td>\n",
       "      <td>0.787456</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.761661</td>\n",
       "      <td>0.776182</td>\n",
       "      <td>0.818576</td>\n",
       "      <td>0.771867</td>\n",
       "      <td>0.826708</td>\n",
       "      <td>0.819196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acc_by_package_fn</th>\n",
       "      <td>0.583815</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.687861</td>\n",
       "      <td>0.612717</td>\n",
       "      <td>0.658960</td>\n",
       "      <td>0.572254</td>\n",
       "      <td>0.670520</td>\n",
       "      <td>0.601156</td>\n",
       "      <td>0.610465</td>\n",
       "      <td>0.627907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Fold 1      Fold 2      Fold 3      Fold 4      Fold 5  \\\n",
       "TP                  25.250000   27.750000   29.750000   26.500000   28.500000   \n",
       "TN                 111.750000  114.250000  116.250000  113.000000  115.000000   \n",
       "FP                  18.000000   15.500000   13.500000   16.750000   14.750000   \n",
       "FN                  18.000000   15.500000   13.500000   16.750000   14.750000   \n",
       "P                   43.250000   43.250000   43.250000   43.250000   43.250000   \n",
       "N                  129.750000  129.750000  129.750000  129.750000  129.750000   \n",
       "TPR                  0.470373    0.470138    0.503194    0.483714    0.467397   \n",
       "TNR                  0.823838    0.846150    0.868231    0.862582    0.847381   \n",
       "FPR                  0.176162    0.153850    0.131769    0.137418    0.152619   \n",
       "FNR                  0.529627    0.529862    0.496806    0.516286    0.532603   \n",
       "Precision            0.379752    0.350000    0.387741    0.394413    0.361048   \n",
       "F1_measure           0.319360    0.295971    0.346246    0.291893    0.262175   \n",
       "Accuracy             0.583815    0.641618    0.687861    0.612717    0.658960   \n",
       "Error_rate           0.416185    0.358382    0.312139    0.387283    0.341040   \n",
       "BACC                 0.647106    0.658144    0.685713    0.673148    0.657389   \n",
       "TSS                  0.294212    0.316288    0.371425    0.346296    0.314777   \n",
       "HSS                  0.178148    0.178146    0.240213    0.192697    0.136996   \n",
       "Brier_score          0.155348    0.157572    0.139540    0.173229    0.147899   \n",
       "AUC                  0.816756    0.811708    0.787456    0.755814    0.761661   \n",
       "Acc_by_package_fn    0.583815    0.641618    0.687861    0.612717    0.658960   \n",
       "\n",
       "                       Fold 6      Fold 7      Fold 8      Fold 9     Fold 10  \n",
       "TP                  24.750000   29.000000   26.000000   26.250000   27.000000  \n",
       "TN                 111.250000  115.500000  112.500000  112.250000  113.000000  \n",
       "FP                  18.500000   14.250000   17.250000   16.750000   16.000000  \n",
       "FN                  18.500000   14.250000   17.250000   16.750000   16.000000  \n",
       "P                   43.250000   43.250000   43.250000   43.000000   43.000000  \n",
       "N                  129.750000  129.750000  129.750000  129.000000  129.000000  \n",
       "TPR                  0.442149    0.485778    0.462508    0.483749    0.493374  \n",
       "TNR                  0.812366    0.853926    0.851611    0.838830    0.855411  \n",
       "FPR                  0.187634    0.146074    0.148389    0.161170    0.144589  \n",
       "FNR                  0.557851    0.514222    0.537492    0.516251    0.506626  \n",
       "Precision            0.227704    0.425887    0.356430    0.344046    0.369376  \n",
       "F1_measure           0.245383    0.332591    0.290421    0.310952    0.334899  \n",
       "Accuracy             0.572254    0.670520    0.601156    0.610465    0.627907  \n",
       "Error_rate           0.427746    0.329480    0.398844    0.389535    0.372093  \n",
       "BACC                 0.627257    0.669852    0.657059    0.661290    0.674392  \n",
       "TSS                  0.254515    0.339704    0.314119    0.322579    0.348785  \n",
       "HSS                  0.109563    0.213132    0.175001    0.182451    0.227613  \n",
       "Brier_score          0.171573    0.141456    0.173214    0.154961    0.163264  \n",
       "AUC                  0.776182    0.818576    0.771867    0.826708    0.819196  \n",
       "Acc_by_package_fn    0.572254    0.670520    0.601156    0.610465    0.627907  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# values to DataFrame \n",
    "value_df = pd.DataFrame(fold_value, columns=[\n",
    "    \"TP\", \"TN\", \"FP\", \"FN\",\"P\",\"N\", \"TPR\", \"TNR\", \"FPR\", \"FNR\", \"Precision\", \"F1_measure\",\n",
    "    \"Accuracy\", \"Error_rate\", \"BACC\", \"TSS\", \"HSS\", \"Brier_score\", \"AUC\", \"Acc_by_package_fn\"\n",
    "])\n",
    " #transpose\n",
    "value_df_nb = value_df.T\n",
    "value_df_nb.columns = [f\"Fold {i+1}\" for i in range(value_df_nb.shape[1])]\n",
    "\n",
    "# display \n",
    "value_df_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4212a095-22f7-4dfc-8694-8d894bffb58c",
   "metadata": {},
   "source": [
    "## 3. Bidirectional-LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175354e8-f8f6-4944-8253-d51dcbf96493",
   "metadata": {},
   "source": [
    "Here I used Bidirectional-LSTM classifier to calculate values like Confusion matrix, Sensitivity, Specificity, False Positive Rate, False Negative Rate, precision, F1 score, Balanced Accuracy, True Skill Statistic, Heidke Skill Score and AUC.\n",
    "The results for each fold are stored for overall evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "807502e2-51d4-4bf9-9ba9-528d22a0946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features \n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# target variable to categorical \n",
    "y = to_categorical(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aec4fe0-f0b2-4e97-a20f-8c1bca4e7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Bidirectional-LSTM model\n",
    "def create_bidirectional_lstm(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))  \n",
    "    model.add(Bidirectional(LSTM(64)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40e36983-cd44-418c-8eb7-a3a506a6c45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CEEDA0F100> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CEF02AB600> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "fold_value = []\n",
    "\n",
    "# Reshape input data to be compatible with LSTM\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "input_shape = (X.shape[1], 1)\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "# Loop through each fold\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X), start=1):\n",
    "    # Splitting the data\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Create and train the Bidirectional-LSTM model\n",
    "    model = create_bidirectional_lstm(input_shape, num_classes)\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "    \n",
    "\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    y_test_class = np.argmax(y_test, axis=1)  \n",
    "    \n",
    "    # Confusion matrix \n",
    "    cm = confusion_matrix(y_test_class, y_pred)\n",
    "    tp = cm.diagonal()  # True Positives \n",
    "    fn = cm.sum(axis=1) - tp  # False Negatives\n",
    "    fp = cm.sum(axis=0) - tp  # False Positives \n",
    "    tn = cm.sum() - (fp + fn + tp)  # True Negatives \n",
    "\n",
    "    p = tp + fn\n",
    "    n = tn + fp\n",
    "\n",
    "    \n",
    "    TPR = tp / (tp + fn)  # Sensitivity \n",
    "    TNR = tn / (tn + fp)  # Specificity \n",
    "    FPR = fp / (fp + tn)  # False Positive Rate \n",
    "    FNR = fn / (fn + tp)  # False Negative Rate s\n",
    "    \n",
    "    Precision = np.divide(tp, (tp + fp), out=np.zeros_like(tp, dtype=float), where=(tp + fp) != 0)\n",
    "    F1_measure = np.divide(2 * (Precision * TPR), (Precision + TPR), out=np.zeros_like(TPR, dtype=float), where=(Precision + TPR) != 0)\n",
    "    \n",
    "    Accuracy = accuracy_score(y_test_class, y_pred)\n",
    "    Error_rate = 1 - Accuracy\n",
    "    BACC = (TPR + TNR) / 2  # Balanced Accuracy \n",
    "    TSS = TPR - FPR  # True Skill Statistic\n",
    "    HSS = (2 * (tp * tn - fp * fn)) / ((tp + fn) * (fn + tn) + (tp + fp) * (fp + tn))  # Heidke Skill Score \n",
    "    \n",
    "    #  Brier Score \n",
    "    brier_score = np.mean([(y_pred_proba[:, i] - (y_test_class == i).astype(int)) ** 2 for i in range(y_pred_proba.shape[1])])\n",
    "    \n",
    "    # AUC\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test_class, y_pred_proba, multi_class='ovr')\n",
    "    except ValueError:\n",
    "        auc = np.nan  # NaN\n",
    "    \n",
    "    # averaged \n",
    "    fold_value.append([\n",
    "        tp.mean(), tn.mean(), fp.mean(), fn.mean(),p.mean(),n.mean(),\n",
    "        TPR.mean(), TNR.mean(), FPR.mean(), FNR.mean(),\n",
    "        Precision.mean(), F1_measure.mean(),\n",
    "        Accuracy, Error_rate, BACC.mean(), TSS.mean(), HSS.mean(),\n",
    "        brier_score, auc, Accuracy  # Acc_by_package_fn \n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6457f840-6bd4-41e0-abeb-a593b3a1685f",
   "metadata": {},
   "source": [
    "### Printing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cc3b5fe-922f-4556-ae08-576c3b64418e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Fold 6</th>\n",
       "      <th>Fold 7</th>\n",
       "      <th>Fold 8</th>\n",
       "      <th>Fold 9</th>\n",
       "      <th>Fold 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>34.250000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>36.750000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>35.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>120.750000</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>123.250000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>123.750000</td>\n",
       "      <td>120.750000</td>\n",
       "      <td>121.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.250000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.750000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.514854</td>\n",
       "      <td>0.590458</td>\n",
       "      <td>0.594948</td>\n",
       "      <td>0.579523</td>\n",
       "      <td>0.538017</td>\n",
       "      <td>0.630528</td>\n",
       "      <td>0.585222</td>\n",
       "      <td>0.708640</td>\n",
       "      <td>0.500450</td>\n",
       "      <td>0.608461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.897660</td>\n",
       "      <td>0.925120</td>\n",
       "      <td>0.913399</td>\n",
       "      <td>0.918318</td>\n",
       "      <td>0.920442</td>\n",
       "      <td>0.903936</td>\n",
       "      <td>0.911227</td>\n",
       "      <td>0.911995</td>\n",
       "      <td>0.918252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.102340</td>\n",
       "      <td>0.074880</td>\n",
       "      <td>0.086601</td>\n",
       "      <td>0.081682</td>\n",
       "      <td>0.079558</td>\n",
       "      <td>0.096064</td>\n",
       "      <td>0.088773</td>\n",
       "      <td>0.088005</td>\n",
       "      <td>0.081748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.485146</td>\n",
       "      <td>0.409542</td>\n",
       "      <td>0.405052</td>\n",
       "      <td>0.420477</td>\n",
       "      <td>0.461983</td>\n",
       "      <td>0.369472</td>\n",
       "      <td>0.414778</td>\n",
       "      <td>0.291360</td>\n",
       "      <td>0.499550</td>\n",
       "      <td>0.391539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.583572</td>\n",
       "      <td>0.605357</td>\n",
       "      <td>0.548649</td>\n",
       "      <td>0.635460</td>\n",
       "      <td>0.667944</td>\n",
       "      <td>0.637117</td>\n",
       "      <td>0.615988</td>\n",
       "      <td>0.881080</td>\n",
       "      <td>0.535658</td>\n",
       "      <td>0.569126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_measure</th>\n",
       "      <td>0.538206</td>\n",
       "      <td>0.588189</td>\n",
       "      <td>0.570525</td>\n",
       "      <td>0.598684</td>\n",
       "      <td>0.581467</td>\n",
       "      <td>0.630344</td>\n",
       "      <td>0.598847</td>\n",
       "      <td>0.735750</td>\n",
       "      <td>0.501134</td>\n",
       "      <td>0.588034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.791908</td>\n",
       "      <td>0.855491</td>\n",
       "      <td>0.849711</td>\n",
       "      <td>0.843931</td>\n",
       "      <td>0.901734</td>\n",
       "      <td>0.843931</td>\n",
       "      <td>0.855491</td>\n",
       "      <td>0.861272</td>\n",
       "      <td>0.808140</td>\n",
       "      <td>0.825581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error_rate</th>\n",
       "      <td>0.208092</td>\n",
       "      <td>0.144509</td>\n",
       "      <td>0.150289</td>\n",
       "      <td>0.156069</td>\n",
       "      <td>0.098266</td>\n",
       "      <td>0.156069</td>\n",
       "      <td>0.144509</td>\n",
       "      <td>0.138728</td>\n",
       "      <td>0.191860</td>\n",
       "      <td>0.174419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BACC</th>\n",
       "      <td>0.696821</td>\n",
       "      <td>0.744059</td>\n",
       "      <td>0.760034</td>\n",
       "      <td>0.746461</td>\n",
       "      <td>0.728167</td>\n",
       "      <td>0.775485</td>\n",
       "      <td>0.744579</td>\n",
       "      <td>0.809933</td>\n",
       "      <td>0.706222</td>\n",
       "      <td>0.763356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSS</th>\n",
       "      <td>0.393642</td>\n",
       "      <td>0.488118</td>\n",
       "      <td>0.520067</td>\n",
       "      <td>0.492921</td>\n",
       "      <td>0.456335</td>\n",
       "      <td>0.550969</td>\n",
       "      <td>0.489159</td>\n",
       "      <td>0.619867</td>\n",
       "      <td>0.412444</td>\n",
       "      <td>0.526713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSS</th>\n",
       "      <td>0.440812</td>\n",
       "      <td>0.509648</td>\n",
       "      <td>0.506150</td>\n",
       "      <td>0.530351</td>\n",
       "      <td>0.519491</td>\n",
       "      <td>0.558978</td>\n",
       "      <td>0.516837</td>\n",
       "      <td>0.657611</td>\n",
       "      <td>0.425696</td>\n",
       "      <td>0.519017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brier_score</th>\n",
       "      <td>0.064741</td>\n",
       "      <td>0.045615</td>\n",
       "      <td>0.049402</td>\n",
       "      <td>0.052035</td>\n",
       "      <td>0.038058</td>\n",
       "      <td>0.059565</td>\n",
       "      <td>0.048623</td>\n",
       "      <td>0.054463</td>\n",
       "      <td>0.065303</td>\n",
       "      <td>0.056488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.963307</td>\n",
       "      <td>0.975613</td>\n",
       "      <td>0.969214</td>\n",
       "      <td>0.962310</td>\n",
       "      <td>0.974933</td>\n",
       "      <td>0.950849</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.942115</td>\n",
       "      <td>0.948917</td>\n",
       "      <td>0.964215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acc_by_package_fn</th>\n",
       "      <td>0.791908</td>\n",
       "      <td>0.855491</td>\n",
       "      <td>0.849711</td>\n",
       "      <td>0.843931</td>\n",
       "      <td>0.901734</td>\n",
       "      <td>0.843931</td>\n",
       "      <td>0.855491</td>\n",
       "      <td>0.861272</td>\n",
       "      <td>0.808140</td>\n",
       "      <td>0.825581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Fold 1      Fold 2      Fold 3      Fold 4      Fold 5  \\\n",
       "TP                  34.250000   37.000000   36.750000   36.500000   39.000000   \n",
       "TN                 120.750000  123.500000  123.250000  123.000000  125.500000   \n",
       "FP                   9.000000    6.250000    6.500000    6.750000    4.250000   \n",
       "FN                   9.000000    6.250000    6.500000    6.750000    4.250000   \n",
       "P                   43.250000   43.250000   43.250000   43.250000   43.250000   \n",
       "N                  129.750000  129.750000  129.750000  129.750000  129.750000   \n",
       "TPR                  0.514854    0.590458    0.594948    0.579523    0.538017   \n",
       "TNR                  0.878788    0.897660    0.925120    0.913399    0.918318   \n",
       "FPR                  0.121212    0.102340    0.074880    0.086601    0.081682   \n",
       "FNR                  0.485146    0.409542    0.405052    0.420477    0.461983   \n",
       "Precision            0.583572    0.605357    0.548649    0.635460    0.667944   \n",
       "F1_measure           0.538206    0.588189    0.570525    0.598684    0.581467   \n",
       "Accuracy             0.791908    0.855491    0.849711    0.843931    0.901734   \n",
       "Error_rate           0.208092    0.144509    0.150289    0.156069    0.098266   \n",
       "BACC                 0.696821    0.744059    0.760034    0.746461    0.728167   \n",
       "TSS                  0.393642    0.488118    0.520067    0.492921    0.456335   \n",
       "HSS                  0.440812    0.509648    0.506150    0.530351    0.519491   \n",
       "Brier_score          0.064741    0.045615    0.049402    0.052035    0.038058   \n",
       "AUC                  0.963307    0.975613    0.969214    0.962310    0.974933   \n",
       "Acc_by_package_fn    0.791908    0.855491    0.849711    0.843931    0.901734   \n",
       "\n",
       "                       Fold 6      Fold 7      Fold 8      Fold 9     Fold 10  \n",
       "TP                  36.500000   37.000000   37.250000   34.750000   35.500000  \n",
       "TN                 123.000000  123.500000  123.750000  120.750000  121.500000  \n",
       "FP                   6.750000    6.250000    6.000000    8.250000    7.500000  \n",
       "FN                   6.750000    6.250000    6.000000    8.250000    7.500000  \n",
       "P                   43.250000   43.250000   43.250000   43.000000   43.000000  \n",
       "N                  129.750000  129.750000  129.750000  129.000000  129.000000  \n",
       "TPR                  0.630528    0.585222    0.708640    0.500450    0.608461  \n",
       "TNR                  0.920442    0.903936    0.911227    0.911995    0.918252  \n",
       "FPR                  0.079558    0.096064    0.088773    0.088005    0.081748  \n",
       "FNR                  0.369472    0.414778    0.291360    0.499550    0.391539  \n",
       "Precision            0.637117    0.615988    0.881080    0.535658    0.569126  \n",
       "F1_measure           0.630344    0.598847    0.735750    0.501134    0.588034  \n",
       "Accuracy             0.843931    0.855491    0.861272    0.808140    0.825581  \n",
       "Error_rate           0.156069    0.144509    0.138728    0.191860    0.174419  \n",
       "BACC                 0.775485    0.744579    0.809933    0.706222    0.763356  \n",
       "TSS                  0.550969    0.489159    0.619867    0.412444    0.526713  \n",
       "HSS                  0.558978    0.516837    0.657611    0.425696    0.519017  \n",
       "Brier_score          0.059565    0.048623    0.054463    0.065303    0.056488  \n",
       "AUC                  0.950849    0.969231    0.942115    0.948917    0.964215  \n",
       "Acc_by_package_fn    0.843931    0.855491    0.861272    0.808140    0.825581  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value to DataFrame\n",
    "value_df = pd.DataFrame(fold_value, columns=[\n",
    "    \"TP\", \"TN\", \"FP\", \"FN\",\"P\",\"N\", \"TPR\", \"TNR\", \"FPR\", \"FNR\", \"Precision\", \"F1_measure\",\n",
    "    \"Accuracy\", \"Error_rate\", \"BACC\", \"TSS\", \"HSS\", \"Brier_score\", \"AUC\", \"Acc_by_package_fn\"\n",
    "])\n",
    "\n",
    "# Transpose\n",
    "value_df_bilstm = value_df.T\n",
    "value_df_bilstm.columns = [f\"Fold {i+1}\" for i in range(value_df_bilstm.shape[1])]\n",
    "\n",
    "# Display\n",
    "value_df_bilstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda421c-9db3-4994-b3ea-6ac7c40834b2",
   "metadata": {},
   "source": [
    "### Average Output\n",
    "In this section I calculae the average of each calculation criteria and show them in a table for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a59e155-3cbe-4247-8762-8a6c2e7337dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Bidirectional-LSTM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>42.400000</td>\n",
       "      <td>27.075000</td>\n",
       "      <td>36.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>128.800000</td>\n",
       "      <td>113.475000</td>\n",
       "      <td>122.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>16.125000</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>16.125000</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>43.200000</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>43.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>129.600000</td>\n",
       "      <td>129.600000</td>\n",
       "      <td>129.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.946574</td>\n",
       "      <td>0.476237</td>\n",
       "      <td>0.585110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.992752</td>\n",
       "      <td>0.846033</td>\n",
       "      <td>0.909914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.007248</td>\n",
       "      <td>0.153967</td>\n",
       "      <td>0.090086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.053426</td>\n",
       "      <td>0.523763</td>\n",
       "      <td>0.414890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.967654</td>\n",
       "      <td>0.359640</td>\n",
       "      <td>0.627995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_measure</th>\n",
       "      <td>0.952773</td>\n",
       "      <td>0.302989</td>\n",
       "      <td>0.593118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.981483</td>\n",
       "      <td>0.626727</td>\n",
       "      <td>0.843719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error_rate</th>\n",
       "      <td>0.018517</td>\n",
       "      <td>0.373273</td>\n",
       "      <td>0.156281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BACC</th>\n",
       "      <td>0.969663</td>\n",
       "      <td>0.661135</td>\n",
       "      <td>0.747512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSS</th>\n",
       "      <td>0.939326</td>\n",
       "      <td>0.322270</td>\n",
       "      <td>0.495024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSS</th>\n",
       "      <td>0.945330</td>\n",
       "      <td>0.183396</td>\n",
       "      <td>0.518459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brier_score</th>\n",
       "      <td>0.016521</td>\n",
       "      <td>0.157806</td>\n",
       "      <td>0.053429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.998755</td>\n",
       "      <td>0.794592</td>\n",
       "      <td>0.962070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acc_by_package_fn</th>\n",
       "      <td>0.981483</td>\n",
       "      <td>0.626727</td>\n",
       "      <td>0.843719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Random Forest  Naive Bayes  Bidirectional-LSTM\n",
       "Values                                                           \n",
       "TP                     42.400000    27.075000           36.450000\n",
       "TN                    128.800000   113.475000          122.850000\n",
       "FP                      0.800000    16.125000            6.750000\n",
       "FN                      0.800000    16.125000            6.750000\n",
       "P                      43.200000    43.200000           43.200000\n",
       "N                     129.600000   129.600000          129.600000\n",
       "TPR                     0.946574     0.476237            0.585110\n",
       "TNR                     0.992752     0.846033            0.909914\n",
       "FPR                     0.007248     0.153967            0.090086\n",
       "FNR                     0.053426     0.523763            0.414890\n",
       "Precision               0.967654     0.359640            0.627995\n",
       "F1_measure              0.952773     0.302989            0.593118\n",
       "Accuracy                0.981483     0.626727            0.843719\n",
       "Error_rate              0.018517     0.373273            0.156281\n",
       "BACC                    0.969663     0.661135            0.747512\n",
       "TSS                     0.939326     0.322270            0.495024\n",
       "HSS                     0.945330     0.183396            0.518459\n",
       "Brier_score             0.016521     0.157806            0.053429\n",
       "AUC                     0.998755     0.794592            0.962070\n",
       "Acc_by_package_fn       0.981483     0.626727            0.843719"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "values = [\n",
    "    \"TP\", \"TN\", \"FP\", \"FN\",\"P\",\"N\", \"TPR\", \"TNR\", \"FPR\", \"FNR\", \n",
    "    \"Precision\", \"F1_measure\", \"Accuracy\", \"Error_rate\", \n",
    "    \"BACC\", \"TSS\", \"HSS\", \"Brier_score\", \"AUC\", \"Acc_by_package_fn\"\n",
    "]\n",
    "\n",
    "# names\n",
    "value_df_rf.index = values\n",
    "value_df_nb.index = values\n",
    "value_df_bilstm.index = values\n",
    "\n",
    "# Calculate the mean\n",
    "avg_value_rf = value_df_rf.mean(axis=1)  # Average Random Forest\n",
    "avg_value_nb = value_df_nb.mean(axis=1)  # Average  Naive Bayes\n",
    "avg_value_bilstm = value_df_bilstm.mean(axis=1)  # Average Bidirectional LSTM \n",
    "\n",
    "# averages to DataFrame\n",
    "avg_values_combined = pd.DataFrame({\n",
    "    \"Random Forest\": avg_value_rf,\n",
    "    \"Naive Bayes\": avg_value_nb,\n",
    "    \"Bidirectional-LSTM\": avg_value_bilstm\n",
    "})\n",
    "\n",
    "#index name \n",
    "avg_values_combined.index.name = \"Values\"\n",
    "\n",
    "# Display \n",
    "avg_values_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3525ad-e3f5-4eac-8b4e-d84752e91027",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "The Random Forest model is the best performer among the three, \n",
    "with the highest accuracy (98.15%), precision (96.77%), True positive rate (TPR) (94.65%), and F1-measure (95.28%), \n",
    "as well as the lowest error rate (1.82%). It consistently delivers the most reliable results across all metrics. \n",
    "Bidirectional-LSTM performs moderately well, with an accuracy of 85.99%, but falls short compared to Random Forest. \n",
    "Naive Bayes, however, performs poorly, with a low accuracy of 62.67% and high error rate (37.33%), making it the least suitable option. \n",
    "Therefore, Random Forest is the best choice for this task, while Bidirectional-LSTM may be considered for sequential data, \n",
    "and Naive Bayes should be avoided."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
